{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMb2eLIsC4wso6FLueMMNE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BillWorstell/TruthInTranslation/blob/main/TranslateModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a **minimal-change** solution demonstrating three fixes/updates:\n",
        "\n",
        "1. **Omit the `system` role** (and optionally `temperature`) for models that don’t allow them.  \n",
        "2. **Properly skip** any models whose sheets already exist.  \n",
        "3. **Log execution time** for each model in addition to cost.  \n",
        "\n",
        "The rest of the code is unchanged, so it *should* preserve your successful outputs in the workbook and only run new models (or newly added ones) that don’t already have a sheet.\n",
        "\n",
        "---\n",
        "\n",
        "### Snippet\n",
        "\n",
        "```python\n",
        "import os\n",
        "import time\n",
        "import openai\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "###############################################################################\n",
        "# 0) SETUP: Provide your key, model list, cost table, usage stats, etc.\n",
        "###############################################################################\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
        "\n",
        "# You can use your existing model list\n",
        "models_to_run = [\n",
        "    \"gpt-4o\",\n",
        "    \"gpt-4o-mini\",\n",
        "    \"o3-mini\",\n",
        "    \"o1-mini\",\n",
        "    # plus any other older models if you want\n",
        "]\n",
        "\n",
        "# Price table (per 1M tokens) for your models (same as before)\n",
        "COST_TABLE = {\n",
        "    \"gpt-4o\":       {\"input\": 2.50/1_000_000,  \"cached_input\": 1.25/1_000_000, \"output\": 10.00/1_000_000},\n",
        "    \"gpt-4o-mini\":  {\"input\": 0.15/1_000_000,  \"cached_input\": 0.075/1_000_000,\"output\": 0.60/1_000_000},\n",
        "    \"o3-mini\":      {\"input\": 1.10/1_000_000,  \"cached_input\": 0.55/1_000_000, \"output\": 4.40/1_000_000},\n",
        "    \"o1-mini\":      {\"input\": 1.10/1_000_000,  \"cached_input\": 0.55/1_000_000, \"output\": 4.40/1_000_000},\n",
        "    # etc.\n",
        "}\n",
        "\n",
        "# For usage/cost tracking per model\n",
        "USAGE_STATS = {m: {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"cost_usd\": 0.0} for m in models_to_run}\n",
        "\n",
        "# Two sets for checking whether a model supports system-role or temperature\n",
        "MODELS_THAT_ALLOW_SYSTEM = (\"gpt-3.5\", \"gpt-4\")  # Extend if needed\n",
        "MODELS_THAT_ALLOW_TEMPERATURE = (\"gpt-3.5\", \"gpt-4\")  # Extend if needed\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 1) Usage Stats Helpers (unchanged except for the “system role” check)\n",
        "###############################################################################\n",
        "def update_usage_stats(response):\n",
        "    model_used = response.model  # e.g. \"o3-mini-2025-03-01\"\n",
        "    usage = response.usage\n",
        "    pt = usage.prompt_tokens\n",
        "    ct = usage.completion_tokens\n",
        "\n",
        "    for short_name in COST_TABLE.keys():\n",
        "        if model_used.startswith(short_name):\n",
        "            USAGE_STATS[short_name][\"prompt_tokens\"] += pt\n",
        "            USAGE_STATS[short_name][\"completion_tokens\"] += ct\n",
        "            cost_in = pt * COST_TABLE[short_name][\"input\"]\n",
        "            cost_out = ct * COST_TABLE[short_name][\"output\"]\n",
        "            USAGE_STATS[short_name][\"cost_usd\"] += (cost_in + cost_out)\n",
        "            break\n",
        "\n",
        "def print_usage_stats():\n",
        "    print(\"\\n=== USAGE & COST SUMMARY ===\")\n",
        "    total = 0.0\n",
        "    for m, st in USAGE_STATS.items():\n",
        "        if st[\"prompt_tokens\"] or st[\"completion_tokens\"]:\n",
        "            print(f\"Model: {m}\")\n",
        "            print(f\"  Prompt Tokens: {st['prompt_tokens']} | Completion Tokens: {st['completion_tokens']}\")\n",
        "            print(f\"  Subtotal Cost: ${st['cost_usd']:.4f}\\n\")\n",
        "            total += st[\"cost_usd\"]\n",
        "    print(f\"OVERALL COST: ${total:.4f}\")\n",
        "    print(\"===========================\\n\")\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 2) Translation Function: Minimal changes\n",
        "###############################################################################\n",
        "def translate_akan_to_english(model_name, text):\n",
        "    \"\"\"\n",
        "    Calls the OpenAI ChatCompletion API to translate the given Akan text\n",
        "    into English using the specified model. Includes a detailed footnote.\n",
        "    \"\"\"\n",
        "\n",
        "    footnote_instruction = (\n",
        "        \"Please provide an expanded footnote for the Akan line you are translating. \"\n",
        "        \"The footnote should include:\\n\"\n",
        "        \"1. Literal Translation Mapping\\n\"\n",
        "        \"2. Cultural Context\\n\"\n",
        "        \"3. Translation Clarification\\n\"\n",
        "    )\n",
        "\n",
        "    # For models that do not allow 'system' role, we pass everything as user content.\n",
        "    supports_system_role = any(model_name.startswith(m) for m in MODELS_THAT_ALLOW_SYSTEM)\n",
        "    supports_temperature = any(model_name.startswith(m) for m in MODELS_THAT_ALLOW_TEMPERATURE)\n",
        "\n",
        "    if supports_system_role:\n",
        "        # We can safely use role=\"system\" and role=\"user\".\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful translator from Akan to English.\"},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    f\"Please translate the following Akan text to English and provide the footnote:\\n\"\n",
        "                    f\"{footnote_instruction}\\n\"\n",
        "                    f\"Akan Text: {text}\"\n",
        "                ),\n",
        "            },\n",
        "        ]\n",
        "    else:\n",
        "        # Combine all instructions in a single user message, no system role.\n",
        "        combined_content = (\n",
        "            \"You are a helpful translator from Akan to English.\\n\\n\"\n",
        "            \"Please translate the following Akan text to English and provide the footnote:\\n\"\n",
        "            f\"{footnote_instruction}\\n\"\n",
        "            f\"Akan Text: {text}\"\n",
        "        )\n",
        "        messages = [{\"role\": \"user\", \"content\": combined_content}]\n",
        "\n",
        "    # Build ChatCompletion kwargs\n",
        "    api_kwargs = {\n",
        "        \"model\": model_name,\n",
        "        \"messages\": messages\n",
        "    }\n",
        "    if supports_temperature:\n",
        "        # Some older ChatCompletion models support temperature=0\n",
        "        api_kwargs[\"temperature\"] = 0\n",
        "\n",
        "    response = openai.ChatCompletion.create(**api_kwargs)\n",
        "    update_usage_stats(response)\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 3) Main Loop: skip existing sheets, measure time, etc.\n",
        "###############################################################################\n",
        "input_file = \"/content/drive/My Drive/TruthInTranslation/Akan/Ananse3/AkanEnglishAligned.xlsx\"\n",
        "output_file = \"/content/drive/My Drive/TruthInTranslation/Akan/Ananse3/Models.xlsx\"\n",
        "\n",
        "df_reference = pd.read_excel(input_file, sheet_name=\"Sheet1\")\n",
        "df_reference.columns = [\"AKAN\", \"ENGLISH\"]\n",
        "\n",
        "# Get existing sheets (so we only run new models)\n",
        "if os.path.exists(output_file):\n",
        "    existing_sheets = pd.ExcelFile(output_file).sheet_names\n",
        "else:\n",
        "    existing_sheets = []\n",
        "\n",
        "model_dataframes = {}\n",
        "for model_name in models_to_run:\n",
        "    if model_name in existing_sheets:\n",
        "        print(f\"Skipping model '{model_name}' - sheet already exists in {output_file}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Running model: {model_name}\")\n",
        "    time_start = time.time()\n",
        "\n",
        "    df_model = df_reference.copy()\n",
        "    df_model.columns = [\"AKAN\", model_name]\n",
        "\n",
        "    # Translate each row\n",
        "    for idx in range(len(df_model)):\n",
        "        akan_text = df_model.loc[idx, \"AKAN\"]\n",
        "        translated = translate_akan_to_english(model_name, akan_text)\n",
        "        df_model.loc[idx, model_name] = translated\n",
        "\n",
        "    model_dataframes[model_name] = df_model\n",
        "\n",
        "    # Log time for just this model\n",
        "    time_end = time.time()\n",
        "    elapsed_sec = time_end - time_start\n",
        "    print(f\"Model '{model_name}' completed in {elapsed_sec:.2f} seconds.\\n\")\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 4) Write new sheets, preserving old ones\n",
        "###############################################################################\n",
        "existing_dfs = {}\n",
        "if os.path.exists(output_file):\n",
        "    with pd.ExcelFile(output_file) as xls:\n",
        "        for sheet in xls.sheet_names:\n",
        "            existing_dfs[sheet] = pd.read_excel(xls, sheet_name=sheet)\n",
        "\n",
        "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
        "    # Re-write old sheets\n",
        "    for sheet, df in existing_dfs.items():\n",
        "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
        "\n",
        "    # Add new model sheets\n",
        "    for model_name, df_model in model_dataframes.items():\n",
        "        df_model.to_excel(writer, sheet_name=model_name, index=False)\n",
        "\n",
        "    # Optional: update a Metadata sheet if you want\n",
        "    if \"Metadata\" not in existing_dfs:\n",
        "        df_metadata = pd.DataFrame({\n",
        "            \"TimeStamp\": [datetime.now().isoformat()],\n",
        "            \"ModelsUsed\": [\", \".join(models_to_run)],\n",
        "            \"NumLines\": [len(df_reference)],\n",
        "            \"Notes\": [\"Detailed translations with expanded footnotes and time/cost logging.\"],\n",
        "        })\n",
        "        df_metadata.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
        "\n",
        "print(f\"\\nDone! Created or updated '{output_file}' with new model sheets.\")\n",
        "print_usage_stats()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Explanation of the Three Key Fixes\n",
        "\n",
        "1. **Omit “system” Role for Certain Models**  \n",
        "   - We now check if the model’s name *starts with* `\"gpt-3.5\"` or `\"gpt-4\"`. If *not*, we bundle everything into the `\"user\"` role.  \n",
        "   - This avoids “`Unsupported value: messages[0].role` does not support 'system'`” errors.  \n",
        "\n",
        "2. **Properly Skip Already-Existing Sheets**  \n",
        "   - Before running each model, we do:  \n",
        "     ```python\n",
        "     if model_name in existing_sheets:\n",
        "         print(f\"Skipping model '{model_name}' - sheet already exists\")\n",
        "         continue\n",
        "     ```\n",
        "   - This ensures we don’t re-run or overwrite a sheet that was successful on a previous run.  \n",
        "\n",
        "3. **Log Execution Time**  \n",
        "   - Right before we start calling `translate_akan_to_english`, we store `time_start = time.time()`.  \n",
        "   - After finishing the loop for that model, we do `time_end = time.time()`.  \n",
        "   - We print out how many seconds that model took: `elapsed_sec = time_end - time_start`.  \n",
        "\n",
        "Everything else remains as close as possible to your previous code so that you keep your successful runs."
      ],
      "metadata": {
        "id": "bDwLEWQXuPsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensure you have the OpenAI Python library installed (pip install openai) and access to an OpenAI API key."
      ],
      "metadata": {
        "id": "umyKpQGCiF6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install openai\n",
        "!pip install openai==0.28\n",
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf6125b-2813-406c-f335-74e80caf662f",
        "id": "uSAK4JgdgzHn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.11/dist-packages (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "#openai.api_key = \"YOUR_OPENAI_API_KEY\"\n"
      ],
      "metadata": {
        "id": "3KXvSK5kaRCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify Input File"
      ],
      "metadata": {
        "id": "jlQPQIM-VWjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAzjrViPUrQq",
        "outputId": "a9bdba73-0735-4cf8-a665-54a7f0a0bf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = \"/content/drive/My Drive/TruthInTranslation/Akan/Ananse10/AkanEnglishAligned.xlsx\"\n",
        "output_file = \"/content/drive/My Drive/TruthInTranslation/Akan/Ananse10/Models.xlsx\""
      ],
      "metadata": {
        "id": "o5I-cIMjVcxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Output File"
      ],
      "metadata": {
        "id": "0HWp96cfWEiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import openai\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "###############################################################################\n",
        "# 0) SETUP: Provide your key, model list, cost table, usage stats, etc.\n",
        "###############################################################################\n",
        "#openai.api_key = \"YOUR_OPENAI_API_KEY\"\n",
        "\n",
        "# You can use your existing model list\n",
        "models_to_run = [\n",
        "    \"gpt-4o\",\n",
        "    \"gpt-4o-mini\",\n",
        "    \"o3-mini\",\n",
        "    \"o1-mini\",\n",
        "    # plus any other older models if you want\n",
        "]\n",
        "\n",
        "# Price table (per 1M tokens) for your models (same as before)\n",
        "COST_TABLE = {\n",
        "    \"gpt-4o\":       {\"input\": 2.50/1_000_000,  \"cached_input\": 1.25/1_000_000, \"output\": 10.00/1_000_000},\n",
        "    \"gpt-4o-mini\":  {\"input\": 0.15/1_000_000,  \"cached_input\": 0.075/1_000_000,\"output\": 0.60/1_000_000},\n",
        "    \"o3-mini\":      {\"input\": 1.10/1_000_000,  \"cached_input\": 0.55/1_000_000, \"output\": 4.40/1_000_000},\n",
        "    \"o1-mini\":      {\"input\": 1.10/1_000_000,  \"cached_input\": 0.55/1_000_000, \"output\": 4.40/1_000_000},\n",
        "    # etc.\n",
        "}\n",
        "\n",
        "# For usage/cost tracking per model\n",
        "USAGE_STATS = {m: {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"cost_usd\": 0.0} for m in models_to_run}\n",
        "\n",
        "# Two sets for checking whether a model supports system-role or temperature\n",
        "MODELS_THAT_ALLOW_SYSTEM = (\"gpt-3.5\", \"gpt-4\")  # Extend if needed\n",
        "MODELS_THAT_ALLOW_TEMPERATURE = (\"gpt-3.5\", \"gpt-4\")  # Extend if needed\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 1) Usage Stats Helpers (unchanged except for the “system role” check)\n",
        "###############################################################################\n",
        "def update_usage_stats(response):\n",
        "    model_used = response.model  # e.g. \"o3-mini-2025-03-01\"\n",
        "    usage = response.usage\n",
        "    pt = usage.prompt_tokens\n",
        "    ct = usage.completion_tokens\n",
        "\n",
        "    for short_name in COST_TABLE.keys():\n",
        "        if model_used.startswith(short_name):\n",
        "            USAGE_STATS[short_name][\"prompt_tokens\"] += pt\n",
        "            USAGE_STATS[short_name][\"completion_tokens\"] += ct\n",
        "            cost_in = pt * COST_TABLE[short_name][\"input\"]\n",
        "            cost_out = ct * COST_TABLE[short_name][\"output\"]\n",
        "            USAGE_STATS[short_name][\"cost_usd\"] += (cost_in + cost_out)\n",
        "            break\n",
        "\n",
        "def print_usage_stats():\n",
        "    print(\"\\n=== USAGE & COST SUMMARY ===\")\n",
        "    total = 0.0\n",
        "    for m, st in USAGE_STATS.items():\n",
        "        if st[\"prompt_tokens\"] or st[\"completion_tokens\"]:\n",
        "            print(f\"Model: {m}\")\n",
        "            print(f\"  Prompt Tokens: {st['prompt_tokens']} | Completion Tokens: {st['completion_tokens']}\")\n",
        "            print(f\"  Subtotal Cost: ${st['cost_usd']:.4f}\\n\")\n",
        "            total += st[\"cost_usd\"]\n",
        "    print(f\"OVERALL COST: ${total:.4f}\")\n",
        "    print(\"===========================\\n\")\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 2) Translation Function: Minimal changes\n",
        "###############################################################################\n",
        "def translate_akan_to_english(model_name, text):\n",
        "    \"\"\"\n",
        "    Calls the OpenAI ChatCompletion API to translate the given Akan text\n",
        "    into English using the specified model. Includes a detailed footnote.\n",
        "    \"\"\"\n",
        "\n",
        "    footnote_instruction = (\n",
        "        \"Please provide an expanded footnote for the Akan line you are translating. \"\n",
        "        \"The footnote should include:\\n\"\n",
        "        \"1. Literal Translation Mapping\\n\"\n",
        "        \"2. Cultural Context\\n\"\n",
        "        \"3. Translation Clarification\\n\"\n",
        "    )\n",
        "\n",
        "    # For models that do not allow 'system' role, we pass everything as user content.\n",
        "    supports_system_role = any(model_name.startswith(m) for m in MODELS_THAT_ALLOW_SYSTEM)\n",
        "    supports_temperature = any(model_name.startswith(m) for m in MODELS_THAT_ALLOW_TEMPERATURE)\n",
        "\n",
        "    if supports_system_role:\n",
        "        # We can safely use role=\"system\" and role=\"user\".\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful translator from Akan to English.\"},\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": (\n",
        "                    f\"Please translate the following Akan text to English and provide the footnote:\\n\"\n",
        "                    f\"{footnote_instruction}\\n\"\n",
        "                    f\"Akan Text: {text}\"\n",
        "                ),\n",
        "            },\n",
        "        ]\n",
        "    else:\n",
        "        # Combine all instructions in a single user message, no system role.\n",
        "        combined_content = (\n",
        "            \"You are a helpful translator from Akan to English.\\n\\n\"\n",
        "            \"Please translate the following Akan text to English and provide the footnote:\\n\"\n",
        "            f\"{footnote_instruction}\\n\"\n",
        "            f\"Akan Text: {text}\"\n",
        "        )\n",
        "        messages = [{\"role\": \"user\", \"content\": combined_content}]\n",
        "\n",
        "    # Build ChatCompletion kwargs\n",
        "    api_kwargs = {\n",
        "        \"model\": model_name,\n",
        "        \"messages\": messages\n",
        "    }\n",
        "    if supports_temperature:\n",
        "        # Some older ChatCompletion models support temperature=0\n",
        "        api_kwargs[\"temperature\"] = 0\n",
        "\n",
        "    response = openai.ChatCompletion.create(**api_kwargs)\n",
        "    update_usage_stats(response)\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 3) Main Loop: skip existing sheets, measure time, etc.\n",
        "###############################################################################\n",
        "#input_file = \"/content/drive/My Drive/TruthInTranslation/Akan/Ananse3/AkanEnglishAligned.xlsx\"\n",
        "#output_file = \"/content/drive/My Drive/TruthInTranslation/Akan/Ananse3/Models.xlsx\"\n",
        "\n",
        "df_reference = pd.read_excel(input_file, sheet_name=\"Sheet1\")\n",
        "df_reference.columns = [\"AKAN\", \"ENGLISH\"]\n",
        "\n",
        "# Get existing sheets (so we only run new models)\n",
        "if os.path.exists(output_file):\n",
        "    existing_sheets = pd.ExcelFile(output_file).sheet_names\n",
        "else:\n",
        "    existing_sheets = []\n",
        "\n",
        "model_dataframes = {}\n",
        "for model_name in models_to_run:\n",
        "    if model_name in existing_sheets:\n",
        "        print(f\"Skipping model '{model_name}' - sheet already exists in {output_file}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Running model: {model_name}\")\n",
        "    time_start = time.time()\n",
        "\n",
        "    df_model = df_reference.copy()\n",
        "    df_model.columns = [\"AKAN\", model_name]\n",
        "\n",
        "    # Translate each row\n",
        "    for idx in range(len(df_model)):\n",
        "        akan_text = df_model.loc[idx, \"AKAN\"]\n",
        "        translated = translate_akan_to_english(model_name, akan_text)\n",
        "        df_model.loc[idx, model_name] = translated\n",
        "\n",
        "    model_dataframes[model_name] = df_model\n",
        "\n",
        "    # Log time for just this model\n",
        "    time_end = time.time()\n",
        "    elapsed_sec = time_end - time_start\n",
        "    print(f\"Model '{model_name}' completed in {elapsed_sec:.2f} seconds.\\n\")\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 4) Write new sheets, preserving old ones\n",
        "###############################################################################\n",
        "existing_dfs = {}\n",
        "if os.path.exists(output_file):\n",
        "    with pd.ExcelFile(output_file) as xls:\n",
        "        for sheet in xls.sheet_names:\n",
        "            existing_dfs[sheet] = pd.read_excel(xls, sheet_name=sheet)\n",
        "\n",
        "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
        "    # Re-write old sheets\n",
        "    for sheet, df in existing_dfs.items():\n",
        "        df.to_excel(writer, sheet_name=sheet, index=False)\n",
        "\n",
        "    # Add new model sheets\n",
        "    for model_name, df_model in model_dataframes.items():\n",
        "        df_model.to_excel(writer, sheet_name=model_name, index=False)\n",
        "\n",
        "    # Optional: update a Metadata sheet if you want\n",
        "    if \"Metadata\" not in existing_dfs:\n",
        "        df_metadata = pd.DataFrame({\n",
        "            \"TimeStamp\": [datetime.now().isoformat()],\n",
        "            \"ModelsUsed\": [\", \".join(models_to_run)],\n",
        "            \"NumLines\": [len(df_reference)],\n",
        "            \"Notes\": [\"Detailed translations with expanded footnotes and time/cost logging.\"],\n",
        "        })\n",
        "        df_metadata.to_excel(writer, sheet_name=\"Metadata\", index=False)\n",
        "\n",
        "print(f\"\\nDone! Created or updated '{output_file}' with new model sheets.\")\n",
        "print_usage_stats()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beGvvmySuisn",
        "outputId": "e6c0dcaa-c963-40c0-a68a-10a386a1ecfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model: gpt-4o\n",
            "Model 'gpt-4o' completed in 198.61 seconds.\n",
            "\n",
            "Running model: gpt-4o-mini\n",
            "Model 'gpt-4o-mini' completed in 178.05 seconds.\n",
            "\n",
            "Running model: o3-mini\n",
            "Model 'o3-mini' completed in 439.29 seconds.\n",
            "\n",
            "Running model: o1-mini\n",
            "Model 'o1-mini' completed in 254.12 seconds.\n",
            "\n",
            "\n",
            "Done! Created or updated '/content/drive/My Drive/TruthInTranslation/Akan/Ananse10/Models.xlsx' with new model sheets.\n",
            "\n",
            "=== USAGE & COST SUMMARY ===\n",
            "Model: gpt-4o\n",
            "  Prompt Tokens: 5642 | Completion Tokens: 19383\n",
            "  Subtotal Cost: $0.2079\n",
            "\n",
            "Model: o3-mini\n",
            "  Prompt Tokens: 2686 | Completion Tokens: 59041\n",
            "  Subtotal Cost: $0.2627\n",
            "\n",
            "Model: o1-mini\n",
            "  Prompt Tokens: 2958 | Completion Tokens: 35928\n",
            "  Subtotal Cost: $0.1613\n",
            "\n",
            "OVERALL COST: $0.6320\n",
            "===========================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}